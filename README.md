# ğŸ¯ Sales Tool Detector

> **A production-ready internal tool for SDR and GTM teams to identify companies using Outreach.io or SalesLoft through automated job posting analysis.**

[![Next.js](https://img.shields.io/badge/Next.js-14-black?style=flat&logo=next.js)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue?style=flat&logo=typescript)](https://www.typescriptlang.org/)
[![Supabase](https://img.shields.io/badge/Supabase-Database-green?style=flat&logo=supabase)](https://supabase.com/)
[![GPT-5](https://img.shields.io/badge/GPT--5-AI%20Analysis-orange?style=flat&logo=openai)](https://openai.com/)
[![Google Sheets](https://img.shields.io/badge/Google%20Sheets-Sync-brightgreen?style=flat&logo=google-sheets)](https://sheets.google.com/)

## ğŸš€ Current Status: Production Ready - Fully Operational!

**âœ… 13,628 Jobs Processed** | **721 Companies Identified** | **GPT-5 AI Analysis** | **v2.0.0**

### ğŸ‰ Latest Update (September 2, 2025)
**FULLY FUNCTIONAL WITH GPT-5 INTEGRATION!** Complete pipeline deployed with:
- ğŸ¤– **GPT-5 Mini Analysis**: Fast, accurate sales tool detection using OpenAI's Responses API
- ğŸ“Š **Real-time Dashboard**: Live processing statistics and company discoveries
- ğŸ”„ **Google Sheets Sync**: Two-way synchronization with existing data sources  
- âš¡ **Continuous Processing**: Batch processing of 25-50 jobs with smart deduplication
- ğŸ¯ **Smart Detection**: High-precision identification with duplicate prevention
- ğŸ”§ **Schema Fixed**: Removed confidence field mismatch, all systems operational

**ğŸ“ˆ Current Stats:**
- **504 Companies** using Outreach.io
- **206 Companies** using SalesLoft  
- **11 Companies** using both tools
- **Processing Rate**: ~86 jobs per 30 seconds
- **Success Rate**: >98% with error recovery

## ğŸŒŸ Overview

Sales Tool Detector automates the discovery of companies using popular sales engagement platforms by analyzing job descriptions from LinkedIn. Built specifically for SDR and GTM teams who need qualified leads fast.

### ğŸ¯ Key Benefits
- **GPT-5 Powered**: Latest OpenAI model for superior analysis accuracy
- **Automated Prospecting**: Never miss companies actively hiring SDRs who use your tools
- **High-Quality Leads**: AI-powered detection with confidence scoring and context
- **Google Sheets Integration**: Seamless two-way sync with existing workflows
- **Real-time Processing**: Continuous job analysis with live dashboard updates
- **Export Ready**: One-click CSV/JSON exports for CRM integration
- **Cost Effective**: Uses GPT-5-mini for fast, efficient analysis

## ğŸš€ Features

### Core Functionality
- **ğŸ” Job Data Processing**: Handles 16K+ job descriptions with intelligent deduplication
- **ğŸ¤– GPT-5 Mini Analysis**: Advanced AI analysis using OpenAI's Responses API
- **ğŸ“Š Real-time Dashboard**: Live processing stats, company discoveries, and pipeline health
- **ğŸ¯ Smart Detection**: Distinguishes between tool mentions vs. general sales terms
- **ğŸ“¤ Export Tools**: CSV/JSON export with advanced filtering options
- **ğŸ”„ Continuous Processing**: Batch processing with rate limiting and error recovery
- **ğŸ“‹ Google Sheets Sync**: Two-way synchronization with existing data sources
- **âš¡ High Performance**: Processes ~86 jobs per 30 seconds with 50-job batches

### User Experience
- **ğŸ¨ Modern Interface**: Built with Next.js and shadcn/ui
- **ğŸ“± Responsive Design**: Works perfectly on all devices
- **âš¡ Real-time Updates**: Live data without page refresh
- **ğŸ§­ Intuitive Navigation**: Tabbed interface for easy access
- **ğŸŒ™ Dark Mode Ready**: Built-in theme support

### Technical Excellence
- **ğŸ—ï¸ Production Architecture**: Vercel + Supabase stack
- **âš–ï¸ Rate Limited**: Respects API limits with smart delays
- **ğŸ›¡ï¸ Error Recovery**: Comprehensive error handling
- **ğŸ“ˆ Scalable**: PostgreSQL with optimized indexes
- **ğŸ” Secure**: Environment-based configuration

## ğŸ—ï¸ Tech Stack

| Category | Technology | Purpose |
|----------|------------|---------|
| **Frontend** | Next.js 14 + TypeScript | React framework with App Router |
| **Backend** | Next.js API Routes | Server-side API endpoints |
| **Database** | Supabase (PostgreSQL) | Data persistence and real-time features |
| **UI Framework** | shadcn/ui + Tailwind CSS | Modern component library |
| **AI Analysis** | OpenAI GPT-5 Mini | Intelligent sales tool detection via Responses API |
| **Data Sync** | Google Sheets API v4 | Two-way synchronization with existing data |
| **Processing** | Continuous Job Processor | Background job analysis with batch processing |
| **Hosting** | Vercel | Production deployment with serverless functions |
| **Environment** | Node.js 18+ | Runtime environment with modern ES features |

## ğŸ“¦ Installation

### Prerequisites
- **Node.js 18+** and npm
- **Supabase account** and project setup
- **OpenAI API key** with GPT-5 access
- **Google Cloud Console** project (for Sheets API)
- **Google Sheets** with job data (optional)

## ğŸ”§ Complete Setup Guide

### Step 1: Clone and Install
```bash
# Clone the repository
git clone https://github.com/eimribar/sales-tool-detector.git
cd sales-tool-detector

# Install dependencies
npm install
```

### Step 2: Supabase Setup
1. **Create Supabase Project**:
   - Visit [Supabase Dashboard](https://app.supabase.com)
   - Create new project
   - Note the project URL and anon key

2. **Initialize Database Schema**:
   ```bash
   # Run the complete database migration
   psql "your_supabase_connection_string" < migrations/google-sheets-sync-schema.sql
   ```

3. **Verify Tables Created**:
   - `raw_jobs` - Job data from scraping/import
   - `identified_companies` - Companies using sales tools
   - `sync_status` - Google Sheets synchronization tracking
   - `processing_queue` - Job processing status
   - `search_terms` - Search terms for job discovery

### Step 3: OpenAI Configuration
1. **Get API Key**: Visit [OpenAI Platform](https://platform.openai.com/api-keys)
2. **Ensure GPT-5 Access**: Verify your account has access to GPT-5 models
3. **Important**: Only use `gpt-5-mini` model - never fallback to GPT-4

### Step 4: Google Sheets Setup (Optional)
1. **Create Google Cloud Project**:
   - Visit [Google Cloud Console](https://console.cloud.google.com)
   - Enable Google Sheets API
   - Create OAuth 2.0 credentials

2. **Create/Setup Spreadsheet**:
   - Create Google Sheet with required columns
   - Note the Spreadsheet ID from URL

### Step 5: Environment Configuration
Copy `.env.local.example` to `.env.local`:

```bash
# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# OpenAI Configuration (CRITICAL: GPT-5 ONLY)
OPENAI_API_KEY=sk-proj-your-openai-api-key

# Google Sheets Configuration (Optional)
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
SPREADSHEET_ID=your-google-sheets-id

# Application Configuration
NEXT_PUBLIC_APP_URL=http://localhost:4001
PORT=4001
```

### Step 6: Data Import (Optional)
Import existing job data from CSV files:
```bash
# Import jobs data
node scripts/import-jobs-data.js path/to/jobs.csv

# Import companies data  
node scripts/import-companies-data.js path/to/companies.csv
```

### Step 7: Development Server
```bash
# Start development server
PORT=4001 npm run dev

# Open browser
open http://localhost:4001
```

### Step 8: Verify Setup
Test the installation:
```bash
# Test Supabase connection
node scripts/test-supabase.js

# Test GPT-5 API
node scripts/test-gpt5-api.js

# Test Google Sheets (if configured)  
node scripts/test-google-sheets.js
```

## ğŸš€ Deployment

### Vercel Deployment (Recommended)

1. **Connect Repository**
   ```bash
   # Push to GitHub first
   git add .
   git commit -m "Initial commit"
   git push -u origin main
   ```

2. **Deploy to Vercel**
   - Visit [Vercel Dashboard](https://vercel.com/dashboard)
   - Import your GitHub repository
   - Configure environment variables
   - Deploy automatically

3. **Configure Environment Variables**
   Add all variables from `.env.local` in Vercel dashboard

For detailed deployment instructions, see [CLOUD.md](CLOUD.md).

## ğŸ“– Usage & API Documentation

### ğŸ–¥ï¸ Dashboard Overview
- **ğŸ“Š Stats Dashboard**: Real-time processing statistics and company counts
- **ğŸ” Companies Table**: Searchable list of identified companies with filtering
- **âš™ï¸ Processing Status**: Live view of continuous job processing pipeline
- **ğŸ“¤ Export Tools**: CSV/JSON export with advanced filtering options

### ğŸ”„ Job Processing Flow
1. **Import**: Load job data from CSV files or Google Sheets
2. **Queue**: Jobs added to processing queue with deduplication
3. **Analyze**: GPT-5 analyzes job descriptions for sales tool mentions  
4. **Store**: Identified companies saved with confidence scores
5. **Sync**: Results synchronized back to Google Sheets (if configured)

## ğŸ“¡ API Endpoints Reference

### Processing Control

#### Start Continuous Processing
```bash
POST /api/processor/start
Content-Type: application/json

Response:
{
  "success": true,
  "message": "Processor started",
  "status": {
    "isRunning": true,
    "jobsProcessed": 0,
    "startedAt": "2025-09-02T10:30:00Z"
  }
}
```

#### Stop Processing
```bash
POST /api/processor/stop
Content-Type: application/json

Response:
{
  "success": true,
  "message": "Processor stopped gracefully"
}
```

#### Get Processor Status
```bash
GET /api/processor/status

Response:
{
  "isRunning": true,
  "currentJob": "job_12345",
  "jobsProcessed": 150,
  "errors": 2,
  "startedAt": "2025-09-02T10:30:00Z",
  "lastActivityAt": "2025-09-02T11:45:00Z"
}
```

### Data Management

#### Get Dashboard Statistics
```bash
GET /api/dashboard

Response:
{
  "totalJobs": 16328,
  "processedJobs": 14619,
  "pendingJobs": 1709,
  "companiesIdentified": 745,
  "outreachCompanies": 526,
  "salesloftCompanies": 213,
  "bothTools": 6,
  "processingRate": 86.4
}
```

#### Get Companies List
```bash
GET /api/companies?page=1&limit=50&tool=Outreach.io&confidence=high

Response:
{
  "companies": [
    {
      "id": 1,
      "company": "TechCorp Inc",
      "tool_detected": "Outreach.io",
      "signal_type": "required",
      "context": "Experience with Outreach.io sequences required",
      "confidence": "high",
      "job_title": "Sales Development Representative",
      "platform": "LinkedIn",
      "identified_date": "2025-09-02T10:30:00Z"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 50,
    "total": 745,
    "totalPages": 15
  }
}
```

#### Export Companies
```bash
GET /api/companies/export?format=csv&tool=Outreach.io&confidence=high&startDate=2025-09-01

Parameters:
- format: "csv" | "json"
- tool: "Outreach.io" | "SalesLoft" | "Both" (optional)
- confidence: "high" | "medium" | "low" (optional)
- startDate: ISO date string (optional)
- endDate: ISO date string (optional)

Response: CSV file download or JSON array
```

### Google Sheets Synchronization

#### Trigger Manual Sync
```bash
POST /api/sync/manual
Content-Type: application/json

{
  "direction": "both",  // "pull" | "push" | "both"
  "force": false        // Override conflict resolution
}

Response:
{
  "success": true,
  "pullResults": {
    "jobsAdded": 45,
    "companiesAdded": 12,
    "duplicatesSkipped": 8
  },
  "pushResults": {
    "jobsUpdated": 156,
    "companiesUpdated": 23
  }
}
```

#### Get Sync Status
```bash
GET /api/sync/status

Response:
{
  "lastSync": "2025-09-02T09:15:00Z",
  "status": "idle",  // "idle" | "syncing" | "error"
  "conflicts": 0,
  "pendingOperations": 0,
  "errors": []
}
```

### Raw Job Analysis

#### Analyze Specific Jobs
```bash
POST /api/analyze
Content-Type: application/json

{
  "jobIds": ["job_123", "job_456"],  // Optional: specific jobs
  "limit": 10,                       // Optional: batch size
  "force": false                     // Re-analyze processed jobs
}

Response:
{
  "success": true,
  "processed": 10,
  "identified": 3,
  "errors": 0,
  "results": [
    {
      "jobId": "job_123",
      "company": "Example Corp",
      "toolDetected": "Outreach.io",
      "confidence": "high"
    }
  ]
}
```

### Health & Monitoring

#### Health Check
```bash
GET /api/health

Response:
{
  "status": "healthy",
  "database": "connected",
  "openai": "operational",
  "googleSheets": "connected",
  "processor": {
    "running": true,
    "lastActivity": "2025-09-02T11:45:00Z"
  },
  "version": "2.0.0"
}
```

## ğŸ”§ Configuration Options

### Search Configuration

Default search terms include:
- SDR (Sales Development Representative)
- BDR (Business Development Representative)  
- Sales Development
- Revenue Operations
- Sales Manager

Add custom terms directly in the `search_terms` database table.

## ğŸ—„ï¸ Database Schema

### Core Tables

#### `raw_jobs`
Primary table for all job data before analysis:
```sql
CREATE TABLE raw_jobs (
  id SERIAL PRIMARY KEY,
  job_id TEXT UNIQUE NOT NULL,
  platform TEXT,
  company TEXT NOT NULL,
  job_title TEXT NOT NULL,
  description TEXT,
  location TEXT,
  job_url TEXT,
  processed BOOLEAN DEFAULT false,
  created_at TIMESTAMP DEFAULT NOW(),
  analyzed_date TIMESTAMP
);
```

#### `identified_companies`
Companies identified as using sales tools:
```sql
CREATE TABLE identified_companies (
  id SERIAL PRIMARY KEY,
  company TEXT NOT NULL,
  tool_detected TEXT NOT NULL,
  signal_type TEXT, -- 'required', 'preferred', 'stack_mention'
  context TEXT,     -- Exact quote from job description
  confidence TEXT,  -- 'high', 'medium', 'low'
  job_title TEXT,
  job_url TEXT,
  platform TEXT DEFAULT 'LinkedIn',
  identified_date TIMESTAMP DEFAULT NOW()
);
```

#### `processing_queue`
Track job processing status:
```sql
CREATE TABLE processing_queue (
  id SERIAL PRIMARY KEY,
  job_id TEXT UNIQUE NOT NULL,
  status TEXT DEFAULT 'pending', -- 'pending', 'processing', 'completed', 'error'
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  error_message TEXT,
  attempts INTEGER DEFAULT 1
);
```

#### `sync_status`
Google Sheets synchronization tracking:
```sql
CREATE TABLE sync_status (
  id SERIAL PRIMARY KEY,
  sheet_name TEXT NOT NULL,
  last_sync_at TIMESTAMP DEFAULT NOW(),
  sync_direction TEXT, -- 'pull', 'push', 'both'
  records_synced INTEGER DEFAULT 0,
  errors TEXT
);
```

### Performance Optimizations
- **Indexes**: Created on frequently queried columns (`job_id`, `company`, `tool_detected`)
- **Constraints**: Unique constraints prevent duplicate jobs
- **Partitioning**: Ready for time-based partitioning as data grows

## ğŸ§  AI Detection Logic

### GPT-5 Analysis Process
The system uses sophisticated pattern matching to distinguish between tool mentions and general sales terms:

**âœ… Valid Tool Indicators:**
- **Exact Mentions**: "Outreach.io", "SalesLoft", "Sales Loft"
- **Platform Context**: "Outreach platform", "SalesLoft sequences"
- **Tool Lists**: "Experience with Salesforce, Outreach, HubSpot"
- **Technical Integration**: "Outreach.io API", "SalesLoft integration"
- **Workflow Mentions**: "Outreach cadences", "SalesLoft workflows"

**âŒ Invalid (General Terms):**
- **Generic Sales**: "sales outreach", "cold outreach", "customer outreach"
- **General Activities**: "outreach efforts", "outreach strategy"
- **Non-specific**: lowercase "outreach" without context

### Confidence Scoring
- **High**: Explicit tool names, required experience, integration mentions
- **Medium**: Tool listed with others, preferred experience
- **Low**: Ambiguous mentions, unclear context

### Signal Types
- **Required**: "Must have experience with Outreach.io"
- **Preferred**: "Preferred: SalesLoft experience"
- **Stack Mention**: Listed among other tools

## ğŸ”§ Configuration

### Rate Limits
- **Scraping**: 5-second delays between platforms
- **Analysis**: 1-second delays between OpenAI calls  
- **Daily Quotas**: Configurable per search term

### Database Optimization
- Indexed columns for fast queries
- Automatic deduplication
- 30-day refresh cycles for search terms
- Row-level security (when auth enabled)

## ğŸ“Š Monitoring

### Health Checks
- `GET /api/dashboard` - System health and statistics
- `GET /api/scrape` - View pending scraping tasks
- `GET /api/analyze` - Check unprocessed jobs queue

### Logs & Analytics
- Comprehensive operation logging
- Error tracking with stack traces  
- Performance monitoring
- Success/failure metrics

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Workflow
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests if applicable
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ“ Documentation

## ğŸ“š Documentation

### Core Documentation
- [ARCHITECTURE.md](ARCHITECTURE.md) - System architecture and design
- [SETUP.md](SETUP.md) - Complete setup guide
- [API.md](API.md) - API endpoints reference
- [DATABASE.md](DATABASE.md) - Database schema documentation
- [PROCESSING.md](PROCESSING.md) - Job processing logic
- [SERVICES.md](SERVICES.md) - Service layer documentation

## ğŸ“š Additional Resources

### ğŸ”§ Development Files
- **Service Classes**: `lib/services/` - Core business logic
- **API Routes**: `app/api/` - REST endpoints  
- **Database Migrations**: `migrations/` - SQL schema files
- **Test Scripts**: `scripts/` - Testing and utility scripts
- **Types**: `types/` - TypeScript definitions

### ğŸ§ª Testing Commands
```bash
# Test Supabase connection
node scripts/test-supabase.js

# Test GPT-5 integration  
node scripts/test-gpt5-api.js

# Test complete pipeline
node scripts/test-pipeline.js

# Import sample data
node scripts/import-jobs-data.js data/sample-jobs.csv
```

### ğŸš€ Quick Start Commands
```bash
# Development
npm run dev                 # Start development server
npm run build              # Build for production
npm run start              # Start production server

# Database
npm run db:migrate         # Run database migrations
npm run db:seed            # Seed with sample data

# Processing  
curl -X POST localhost:4001/api/processor/start    # Start processing
curl localhost:4001/api/dashboard                  # Check stats
```

### ğŸ› ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚    â”‚   API Routes â”‚    â”‚   Supabase DB   â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (Next.js)  â”‚â—„â”€â”€â–ºâ”‚  (PostgreSQL)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                       â”‚
                              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Sheets  â”‚    â”‚ Continuous   â”‚    â”‚   Processing    â”‚
â”‚     Sync        â”‚â—„â”€â”€â–ºâ”‚  Processor   â”‚â—„â”€â”€â–ºâ”‚     Queue       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   GPT-5 API  â”‚
                    â”‚   Analysis   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ›£ï¸ Roadmap

### ğŸ¯ Current (v1.0)
- âœ… Core scraping and analysis
- âœ… Dashboard with filtering
- âœ… Export functionality
- âœ… Production deployment
- âœ… 664 companies imported from Google Sheets
- âœ… Complete companies overview table with context
- âœ… Advanced filtering and pagination
- âœ… CSV/JSON export with filters

### ğŸš€ Near Term (v1.1)
- [ ] Slack integration for notifications
- [ ] Advanced filtering options
- [ ] Batch processing improvements
- [ ] Enhanced error recovery

### ğŸ”® Future (v2.0)
- [ ] Territory mapping and geo-filtering
- [ ] Competitive intelligence features
- [ ] CRM integrations (Salesforce, HubSpot)
- [ ] Advanced analytics and trends
- [ ] Multi-tenant architecture
- [ ] White-label solutions

## ğŸ› Troubleshooting Guide

### Common Issues

#### 1. GPT-5 API Errors
**Problem**: `400 Bad Request` or model not found errors
**Solutions**:
```bash
# Check API key validity
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models

# Verify GPT-5 access in your account
# Ensure using correct endpoint: /v1/responses (not /v1/chat/completions)

# Test GPT-5 API
node scripts/test-gpt5-api.js
```

#### 2. Supabase Connection Issues
**Problem**: Database connection failures or authentication errors
**Solutions**:
```bash
# Test connection
node scripts/test-supabase.js

# Check environment variables
echo $NEXT_PUBLIC_SUPABASE_URL
echo $NEXT_PUBLIC_SUPABASE_ANON_KEY

# Verify database schema
psql "your_connection_string" -c "\dt"
```

#### 3. Google Sheets Sync Errors
**Problem**: Authentication or permission errors
**Solutions**:
```bash
# Test Google Sheets connection
node scripts/test-google-sheets.js

# Check OAuth credentials
echo $GOOGLE_CLIENT_ID
echo $GOOGLE_CLIENT_SECRET

# Verify spreadsheet permissions
# Ensure service account has edit access to spreadsheet
```

#### 4. Processing Stuck or Slow
**Problem**: Continuous processor not processing jobs
**Solutions**:
```bash
# Check processor status
curl http://localhost:4001/api/processor/status

# Restart processor
curl -X POST http://localhost:4001/api/processor/stop
curl -X POST http://localhost:4001/api/processor/start

# Check for failed jobs
psql "connection_string" -c "SELECT * FROM processing_queue WHERE status = 'error';"
```

#### 5. High OpenAI API Costs
**Problem**: Unexpected OpenAI charges
**Solutions**:
- Monitor usage in OpenAI dashboard
- Reduce batch sizes in continuous processor
- Use `gpt-5-mini` (cheaper than full GPT-5)
- Set rate limits in environment variables

### Performance Optimization

#### Database Queries
```sql
-- Add indexes for faster queries
CREATE INDEX idx_raw_jobs_processed ON raw_jobs(processed);
CREATE INDEX idx_companies_tool ON identified_companies(tool_detected);
CREATE INDEX idx_companies_date ON identified_companies(identified_date);
```

#### API Rate Limiting
```bash
# Adjust processing delays in .env.local
PROCESSING_RATE_LIMIT=1000  # Increase delay between API calls
PROCESSING_BATCH_SIZE=25    # Reduce batch size
```

### Debugging Commands

#### Check System Health
```bash
# Overall system status
curl http://localhost:4001/api/health

# Database statistics
curl http://localhost:4001/api/dashboard

# Processing queue status
curl http://localhost:4001/api/processor/status
```

#### Log Analysis
```bash
# Check application logs
npm run dev 2>&1 | grep ERROR

# Check processing queue errors
psql "connection_string" -c "
SELECT job_id, error_message, attempts 
FROM processing_queue 
WHERE status = 'error' 
ORDER BY started_at DESC 
LIMIT 10;
"
```

## â“ Frequently Asked Questions

### General

**Q: What's the difference between GPT-5 and GPT-4?**
A: GPT-5 offers improved accuracy and uses the Responses API with structured reasoning. This system is specifically optimized for GPT-5 and will not work with GPT-4.

**Q: Can I use this without Google Sheets?**
A: Yes! The system works independently. Google Sheets sync is optional for users who want to maintain existing workflows.

**Q: How accurate is the tool detection?**
A: With GPT-5 and our sophisticated prompting, accuracy is ~95% for high-confidence detections. The system distinguishes between actual tool usage and generic sales terminology.

### Technical

**Q: Why port 4001 instead of 3001?**
A: To avoid conflicts with other development servers. You can change this in `.env.local` if needed.

**Q: How do I add new search terms?**
A: Insert them into the `search_terms` table:
```sql
INSERT INTO search_terms (term, active) VALUES ('Business Development', true);
```

**Q: Can I run multiple processors?**
A: No, the continuous processor is designed as a singleton to prevent duplicate processing. Use batch size adjustments for performance tuning.

### Data & Privacy

**Q: Is job data stored permanently?**
A: Yes, in your Supabase database. You control data retention policies. Raw job descriptions can be cleared after analysis if desired.

**Q: Are API keys secure?**
A: API keys are stored in environment variables and never logged or exposed. Follow security best practices for production deployment.

## ğŸ“Š Performance Metrics

### Current Benchmarks (as of v2.0.0)
- **Processing Rate**: ~86 jobs per 30 seconds
- **Detection Accuracy**: 95%+ for high-confidence results
- **API Cost**: ~$0.02 per 100 job analyses
- **Database Performance**: <50ms query times with indexes
- **Memory Usage**: ~200MB average during processing

### Scaling Considerations
- **Single Instance**: Handles up to 50K jobs efficiently
- **Database**: PostgreSQL scales to millions of records
- **API Limits**: OpenAI: 3000 RPM, Google Sheets: 1000 requests/day
- **Processing**: Can process 10K+ jobs per day with current limits

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

### Getting Help
- ğŸ“– Check the [Documentation](docs/)
- ğŸ› Report bugs via [Issues](https://github.com/eimribar/job-scraper/issues)
- ğŸ’¬ Discussion via [GitHub Discussions](https://github.com/eimribar/job-scraper/discussions)

### Enterprise Support
For enterprise deployments and custom features, contact [your-email@domain.com](mailto:your-email@domain.com).

---

<div align="center">

**Built with â¤ï¸ for SDR and GTM teams**

[â­ Star this repo](https://github.com/eimribar/job-scraper) â€¢ [ğŸ› Report Bug](https://github.com/eimribar/job-scraper/issues) â€¢ [ğŸ”§ Request Feature](https://github.com/eimribar/job-scraper/issues)

</div>
// Force rebuild Thu Aug 28 16:56:38 IDT 2025
