import { ScraperService } from './scraperService';
import { AnalysisService } from './analysisService';
import { DataService } from './dataService';

export interface ProcessingStats {
  searchTerm: string;
  totalScraped: number;
  newJobs: number;
  analyzed: number;
  failed: number;
  startTime: Date;
  endTime?: Date;
}

export class JobProcessor {
  private scraperService: ScraperService;
  private analysisService: AnalysisService;
  private dataService: DataService;
  private isProcessing: boolean = false;
  private currentStats: ProcessingStats | null = null;

  constructor() {
    this.scraperService = new ScraperService();
    this.analysisService = new AnalysisService();
    this.dataService = new DataService();
  }

  /**
   * Process a single search term - scrape, deduplicate, analyze sequentially
   */
  async processSearchTerm(searchTerm: string, maxItems: number = 500): Promise<ProcessingStats> {
    if (this.isProcessing) {
      throw new Error('Already processing. Please wait for current job to complete.');
    }

    this.isProcessing = true;
    
    const stats: ProcessingStats = {
      searchTerm,
      totalScraped: 0,
      newJobs: 0,
      analyzed: 0,
      failed: 0,
      startTime: new Date()
    };

    this.currentStats = stats;

    try {
      console.log(`\nüîç Starting processing for search term: "${searchTerm}"`);
      console.log(`‚è∞ Start time: ${stats.startTime.toISOString()}`);

      // Step 1: Scrape jobs from LinkedIn
      console.log(`üì• Scraping jobs from LinkedIn (max ${maxItems})...`);
      const scrapedJobs = await this.scraperService.scrapeJobs(searchTerm, maxItems);
      stats.totalScraped = scrapedJobs.length;
      console.log(`‚úÖ Scraped ${stats.totalScraped} jobs`);
      
      // Debug: Log first 3 scraped jobs
      console.log('\nüìã Sample of scraped jobs:');
      scrapedJobs.slice(0, 3).forEach((job, idx) => {
        console.log(`  Job ${idx + 1}:`);
        console.log(`    ID: ${job.job_id}`);
        console.log(`    Company: ${job.company}`);
        console.log(`    Title: ${job.job_title}`);
      });

      // Step 2: Check each job ID against database (deduplication)
      console.log('\nüîç Checking for new jobs (deduplication)...');
      console.log(`  Total jobs to check: ${scrapedJobs.length}`);
      const newJobs = [];
      const duplicateJobs = [];
      
      let checkCount = 0;
      for (const job of scrapedJobs) {
        checkCount++;
        if (checkCount <= 5 || checkCount % 50 === 0) {
          console.log(`\n  [${checkCount}/${scrapedJobs.length}] Checking: ${job.job_id}`);
          console.log(`    Company: ${job.company}`);
          console.log(`    Title: ${job.job_title}`);
        }
        
        const exists = await this.dataService.jobExists(job.job_id);
        
        if (!exists) {
          newJobs.push(job);
          if (checkCount <= 5) {
            console.log(`    ‚úÖ NEW job will be saved`);
          }
        } else {
          duplicateJobs.push(job);
          if (checkCount <= 5) {
            console.log(`    ‚è≠Ô∏è  DUPLICATE (already in DB)`);
          }
        }
      }
      
      stats.newJobs = newJobs.length;
      console.log(`üìä Found ${stats.newJobs} new jobs (${duplicateJobs.length} duplicates)`);
      if (duplicateJobs.length > 0) {
        console.log(`  Sample duplicates: ${duplicateJobs.slice(0, 3).map(j => j.company).join(', ')}`);
      }

      // Step 3: Save all NEW jobs marked as ready for analysis
      if (stats.newJobs > 0) {
        console.log('üíæ Saving jobs to database for analysis...');
        
        try {
          // Save all new jobs in batches
          const batchSize = 50;
          for (let i = 0; i < newJobs.length; i += batchSize) {
            const batch = newJobs.slice(i, i + batchSize);
            await this.dataService.saveJobsReadyForAnalysis(batch);
            console.log(`  ‚úÖ Saved batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(newJobs.length/batchSize)} (${batch.length} jobs)`);
            
            // Small delay between batches
            if (i + batchSize < newJobs.length) {
              await this.delay(100);
            }
          }
          
          stats.analyzed = newJobs.length; // All jobs are ready for analysis
          console.log(`üìä Successfully saved ${newJobs.length} jobs ready for analysis`);
          
        } catch (saveError) {
          console.error('‚ùå Failed to save jobs:', saveError);
          stats.failed = newJobs.length;
          throw saveError;
        }
      }

      // Step 4: Update search term status
      await this.dataService.updateSearchTermLastScraped(searchTerm, stats.totalScraped);
      
      stats.endTime = new Date();
      const duration = (stats.endTime.getTime() - stats.startTime.getTime()) / 1000;
      
      console.log(`\n‚úÖ Processing complete for "${searchTerm}"`);
      console.log(`üìä Summary:`);
      console.log(`  - Total scraped: ${stats.totalScraped}`);
      console.log(`  - New jobs: ${stats.newJobs}`);
      console.log(`  - Analyzed: ${stats.analyzed}`);
      console.log(`  - Failed: ${stats.failed}`);
      console.log(`  - Duration: ${Math.round(duration)} seconds (${Math.round(duration/60)} minutes)`);
      
      return stats;
      
    } catch (error) {
      console.error('‚ùå Fatal error during processing:', error);
      stats.endTime = new Date();
      throw error;
    } finally {
      this.isProcessing = false;
      this.currentStats = null;
    }
  }

  /**
   * Process all active search terms sequentially
   */
  async processAllSearchTerms(): Promise<ProcessingStats[]> {
    const allStats: ProcessingStats[] = [];
    
    try {
      // Get all active search terms
      const searchTerms = await this.dataService.getActiveSearchTerms();
      console.log(`\nüöÄ Starting weekly processing for ${searchTerms.length} search terms`);
      
      const startTime = new Date();
      
      // Process each search term sequentially
      for (let i = 0; i < searchTerms.length; i++) {
        const term = searchTerms[i];
        const termNumber = i + 1;
        
        console.log(`\n${'='.repeat(50)}`);
        console.log(`Processing term ${termNumber}/${searchTerms.length}: "${term.search_term}"`);
        console.log(`${'='.repeat(50)}`);
        
        try {
          const stats = await this.processSearchTerm(term.search_term);
          allStats.push(stats);
          
          // Delay between search terms (5 seconds)
          if (i < searchTerms.length - 1) {
            console.log('‚è≥ Waiting 5 seconds before next search term...');
            await this.delay(5000);
          }
          
        } catch (error) {
          console.error(`Failed to process search term "${term.search_term}":`, error);
          // Continue with next search term
          continue;
        }
      }
      
      const endTime = new Date();
      const totalDuration = (endTime.getTime() - startTime.getTime()) / 1000;
      
      // Print final summary
      console.log(`\n${'='.repeat(50)}`);
      console.log('üìä WEEKLY PROCESSING COMPLETE');
      console.log(`${'='.repeat(50)}`);
      console.log(`Total duration: ${Math.round(totalDuration/60)} minutes`);
      
      const totalScraped = allStats.reduce((sum, stat) => sum + stat.totalScraped, 0);
      const totalNew = allStats.reduce((sum, stat) => sum + stat.newJobs, 0);
      const totalAnalyzed = allStats.reduce((sum, stat) => sum + stat.analyzed, 0);
      
      console.log(`Total jobs scraped: ${totalScraped}`);
      console.log(`Total new jobs: ${totalNew}`);
      console.log(`Total analyzed: ${totalAnalyzed}`);
      
      return allStats;
      
    } catch (error) {
      console.error('Fatal error in processAllSearchTerms:', error);
      throw error;
    }
  }

  /**
   * Get current processing status
   */
  getStatus(): { isProcessing: boolean; currentStats: ProcessingStats | null } {
    return {
      isProcessing: this.isProcessing,
      currentStats: this.currentStats
    };
  }

  /**
   * Helper function to create delay
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

export default JobProcessor;